{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityaharshsingh7/ml/blob/main/machinelearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning and preprocessing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"Metro_Interstate_Traffic_Volume.csv\")\n",
        "\n",
        "# Display basic info and check for missing values\n",
        "print(data.head())\n",
        "print(data.describe())\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Drop columns with excessive missing values or irrelevant info\n",
        "data = data.drop(columns=['holiday'])  # 'holiday' column is mostly NaN\n",
        "\n",
        "# Convert 'date_time' to datetime and extract useful time features\n",
        "data['date_time'] = pd.to_datetime(data['date_time'])\n",
        "data['hour'] = data['date_time'].dt.hour\n",
        "data['weekday'] = data['date_time'].dt.weekday\n",
        "data['month'] = data['date_time'].dt.month"
      ],
      "metadata": {
        "id": "IsjFop3AK_WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic visualization\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.plot(data['date_time'], data['traffic_volume'], color='blue')\n",
        "plt.title('Traffic Volume Over Time')\n",
        "plt.xlabel('Date and Time')\n",
        "plt.ylabel('Traffic Volume')\n",
        "plt.show()\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "data = pd.get_dummies(data, columns=['weather_main'], drop_first=True)\n",
        "\n",
        "# Drop columns not needed for modeling\n",
        "data = data.drop(columns=['weather_description', 'date_time'])\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('traffic_volume', axis=1)\n",
        "y = data['traffic_volume']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature selection (optional but improves performance)\n",
        "selector = SelectKBest(score_func=f_regression, k='all')\n",
        "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Define models and parameter grid\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest': RandomForestRegressor(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
        "    'Support Vector Machine': SVR()\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "AFhU3vyLKlfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning for RandomForest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "grid_search.fit(X_train_selected, y_train)\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Ensemble model\n",
        "ensemble_model = VotingRegressor(\n",
        "    estimators=[\n",
        "        ('lr', LinearRegression()),\n",
        "        ('rf', best_rf_model),\n",
        "        ('gb', GradientBoostingRegressor(random_state=42)),\n",
        "        ('svr', SVR())\n",
        "    ]\n",
        ")\n",
        "ensemble_model.fit(X_train_selected, y_train)"
      ],
      "metadata": {
        "id": "NxCFGIlUK4h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final set of models to evaluate\n",
        "final_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest': best_rf_model,\n",
        "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
        "    'Support Vector Machine': SVR(),\n",
        "    'Ensemble': ensemble_model\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in final_models.items():\n",
        "    model.fit(X_train_selected, y_train)\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results[name] = {'MSE': mse, 'R-squared': r2}\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"  MSE: {mse:.2f}\")\n",
        "    print(f\"  R^2: {r2:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "_O7xMT5jKwc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced, clearer visualization\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(y_test.values[:200], label='Actual', color='blue')\n",
        "plt.plot(list(final_models['Ensemble'].predict(X_test_selected))[:200], label='Predicted - Ensemble', color='red')\n",
        "plt.title('Traffic Volume Prediction: Actual vs Ensemble')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Traffic Volume')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-_X5fFPVKvBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5r63fMFYoHiJgL0UV/Jol",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}